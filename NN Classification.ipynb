{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the features with a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler\n",
    "import seaborn\n",
    "from keras.utils import np_utils\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((560, 4096), (560, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(np.load('features.npy'))\n",
    "labels = np.load('labels.npy')\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(np.transpose(np.transpose(labels)[1]))\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(encoded_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.output_shape (None, 7)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 50)                25650     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 7)                 357       \n",
      "=================================================================\n",
      "Total params: 31,107\n",
      "Trainable params: 31,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(512,),activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "#model.add(keras.layers.Dropout(rate=0.5, noise_shape=None, seed=2))\n",
    "model.add(Dense(7,activation=\"softmax\"))\n",
    "print('model.output_shape',model.output_shape)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,verbose=0, epochs=10,validation_split=0.2)\n",
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We add Dropout to reduce the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.output_shape (None, 7)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 50)                25650     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 7)                 357       \n",
      "=================================================================\n",
      "Total params: 31,107\n",
      "Trainable params: 31,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(512,),activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(keras.layers.Dropout(rate=0.3, noise_shape=None, seed=2))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(keras.layers.Dropout(rate=0.2, noise_shape=None, seed=2))\n",
    "model.add(Dense(7,activation=\"softmax\"))\n",
    "print('model.output_shape',model.output_shape)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,verbose=0, epochs=10,validation_split=0.2)\n",
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we test the robustness with training on condition 1,2,3,5 and test on conditon 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtest (112, 4096)\n",
      "Xtrain (448, 4096)\n"
     ]
    }
   ],
   "source": [
    "tool = ['allen','clamp','driver','flat','pen','screw','usb']\n",
    "cond=['cond1','cond2','cond3','cond4','cond5']\n",
    "#print(labels[1][0])\n",
    "#print(len([i for i in labels[1] if i=='cond5']))\n",
    "y_test=[]\n",
    "X_test=[]\n",
    "y_train=[]\n",
    "X_train=[]\n",
    "\n",
    "y = np.array(np.transpose(np.transpose(labels)[1]))\n",
    "conditions = np.array(np.transpose(np.transpose(labels)[0]))\n",
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "for i in range(len(y)):\n",
    "  if conditions[i]=='conditions4':\n",
    "    y_test.append(dummy_y[i])\n",
    "    X_test.append(data[i])\n",
    "  else:\n",
    "    y_train.append(dummy_y[i])\n",
    "    X_train.append(data[i])\n",
    "y_test = np.array(y_test)\n",
    "X_test = np.array(X_test)#les valeurs de la cond4\n",
    "y_train = np.array(y_train)\n",
    "X_train = np.array(X_train)#les valeurs de cond1,2,3,5\n",
    "print('Xtest',X_test.shape)\n",
    "print('Xtrain',X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same network as previously, with the dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.output_shape (None, 7)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 50)                25650     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 7)                 357       \n",
      "=================================================================\n",
      "Total params: 31,107\n",
      "Trainable params: 31,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(512,),activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(keras.layers.Dropout(rate=0.3, noise_shape=None, seed=2))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(keras.layers.Dropout(rate=0.2, noise_shape=None, seed=2))\n",
    "model.add(Dense(7,activation=\"softmax\"))\n",
    "print('model.output_shape',model.output_shape)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,y_train,verbose=0, epochs=20, validation_data=(X_test,y_test))\n",
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
